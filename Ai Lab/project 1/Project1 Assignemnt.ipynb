{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohofgMba8naO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I-gIH8Kx8-cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.1:\n",
        "\n",
        "Get the GPU device, if it is available. Store the device name in the variable device."
      ],
      "metadata": {
        "id": "rRk-kgcY8-Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device=\"mps\"\n",
        "else:\n",
        "    device=\"cpu\""
      ],
      "metadata": {
        "id": "A_JsDxHB9CjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Dataset\n",
        "The data for this assignment is contained in the directory sea_creatures. In this directory, there are two folders. We'll use train to train our classification model, and then submit predictions about the test images to the grader."
      ],
      "metadata": {
        "id": "dOvIpxMt9Dk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"sea_creatures\")"
      ],
      "metadata": {
        "id": "IllFbb1x9Ii7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.2:\n",
        "\n",
        "Find the names of the classes we will be working with. Images for each class are inside folders within the sea_creatures/train folder. Make a list of the class names (each corresponding to a directory name). Your list should be named classes."
      ],
      "metadata": {
        "id": "hSp4viQm9N-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(\"sea_creatures/train\")\n",
        "classes = os.listdir(train_dir)\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "MYFR9kwL9Qrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.3:\n",
        "\n",
        "Build a transformer pipeline. It should ensure the images are in RGB format, scale them to 224\n",
        "224 pixels, and convert them into a PyTorch tensor. You will probably find ConvertToRGB useful."
      ],
      "metadata": {
        "id": "LrUF-EUo9UfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height = 224\n",
        "width = 224\n",
        "\n",
        "\n",
        "class ConvertToRGB:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # ... your steps ...\n",
        "     ConvertToRGB(),\n",
        "\n",
        "\n",
        "    # ... your steps ...\n",
        "      transforms.Resize((224,224)),\n",
        "\n",
        "    # ... your steps ...\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "print(transform)"
      ],
      "metadata": {
        "id": "02Cr_jFh9Wo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.4:\n",
        "\n",
        "Test that the transformer pipeline is working. Load in the specified training image and transform it. Check that you get a 3\n",
        "224\n",
        "224 tensor."
      ],
      "metadata": {
        "id": "_JfxuD5n9bOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file = \"sea_creatures/train/Dolphin/10004986625_0f786ab86b_b.jpg\"\n",
        "\n",
        "image = Image.open (sample_file)# load your image\n",
        "\n",
        "transformed_image = transform(image)\n",
        "print(transformed_image.shape)"
      ],
      "metadata": {
        "id": "o4ksNXIX9fwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Task 1.5.5:\n",
        "\n",
        "Create a DataSet for the training data (using the ImageFolder subclass). It should apply the transformer pipeline."
      ],
      "metadata": {
        "id": "lIXUn4L69lWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir,transform=transform)\n",
        "print(\"Image size\", dataset[0][0].shape)\n",
        "print(\"Label\", dataset[0][1])"
      ],
      "metadata": {
        "id": "oN5zNXC29oEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.6:\n",
        "\n",
        "Calculate the class distribution. Store this in the variable class_distribution as a dictionary. The keys should be the class names. The values should be the number of training samples for the class."
      ],
      "metadata": {
        "id": "BUs2z4Ky9tQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Get counts per class index\n",
        "counts = Counter(x[1] for x in tqdm(dataset))\n",
        "print(\"The counts dictionary:\", counts)\n",
        "\n",
        "# Step 2: Get class-to-index mapping\n",
        "class_to_index = dataset.class_to_idx\n",
        "print(\"The class_to_idx dictionary:\", class_to_index)\n",
        "\n",
        "# Step 3: Map class names to their counts\n",
        "class_distribution = {class_name: counts[idx] for class_name, idx in class_to_index.items()}\n",
        "print(\"Class distribution:\", class_distribution)"
      ],
      "metadata": {
        "id": "9en372Zj9s6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.7:\n",
        "\n",
        "Create a DataLoader that loads from this DataSet in batches of 32."
      ],
      "metadata": {
        "id": "VCuu_I-C92aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset_loader = DataLoader(dataset,batch_size=batch_size)\n",
        "\n",
        "# Get one batch\n",
        "first_batch = next(iter(dataset_loader))\n",
        "\n",
        "print(f\"Shape of one batch: {first_batch[0].shape}\")\n",
        "print(f\"Shape of labels: {first_batch[1].shape}\")"
      ],
      "metadata": {
        "id": "_6iFJ9ct941G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.8: Calculate the mean and standard deviation of each channel in this data set.\n",
        "\n",
        "Fill the missing lines in the get_mean_std function and invoke it with the right dataset.\n",
        "\n",
        "This will calculate the correct values for mean and std."
      ],
      "metadata": {
        "id": "sdX0uUMV97YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_std(loader):\n",
        "    \"\"\"Computes the mean and standard deviation of image data.\n",
        "\n",
        "    Input: a `DataLoader` producing tensors of shape [batch_size, channels, pixels_x, pixels_y]\n",
        "    Output: the mean of each channel as a tensor, the standard deviation of each channel as a tensor\n",
        "            formatted as a tuple (means[channels], std[channels])\"\"\"\n",
        "\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in tqdm(loader):\n",
        "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "        num_batches += 1\n",
        "    # Compute the mean from the channels_sum and num_batches\n",
        "    mean = channels_sum /num_batches\n",
        "    # Compute the standard deviation form channels_squared_sum, num_batches,\n",
        "    # and the mean.\n",
        "\n",
        "    std = (channels_squared_sum / num_batches - mean**2) ** 0.5\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "\n",
        "mean, std = get_mean_std(dataset_loader)\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard deviation: {std}\")"
      ],
      "metadata": {
        "id": "MvDYVpVk98m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.9:\n",
        "\n",
        "Build a new transformer pipeline that normalizes the channels according to the mean and standard deviation above. The pipeline should be assigned to the variable transform_norm. Afterwards, use the pipeline to create a normalized data set and store it in the variable norm_dataset."
      ],
      "metadata": {
        "id": "R_FzIL0N-AJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_norm = transforms.Compose(\n",
        "    [\n",
        "        ConvertToRGB(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ]\n",
        ")\n",
        "print(transform_norm)"
      ],
      "metadata": {
        "id": "-rBjfEu3-DOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dataset =datasets.ImageFolder(root=train_dir,transform=transform_norm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Image size\", norm_dataset[0][0].shape)\n",
        "print(\"Label\", norm_dataset[0][1])"
      ],
      "metadata": {
        "id": "cLBG7D7a-Nlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.10:\n",
        "\n",
        "Split the normalized data set into a training set and a validation set. 80% of the data should be in the training set, and 20% in the validation set."
      ],
      "metadata": {
        "id": "PT6MNGl4-YEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Df2ZJxAJ97Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "train_dataset, val_dataset = random_split(norm_dataset,[0.80,0.20], generator=g)\n",
        "\n",
        "print(\"Training data set size:\", len(train_dataset))\n",
        "print(\"Validation data set size:\", len(val_dataset))"
      ],
      "metadata": {
        "id": "7n1wDmBn-Y_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.11:\n",
        "\n",
        "Set up data loaders for both the training and validation data sets. Use the same batch size as before. Remember to set shuffle=True on the training loader."
      ],
      "metadata": {
        "id": "PIl8T8_o-mBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "U95J8X0G-mtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.12:\n",
        "\n",
        "Start setting up the network. We'll begin with three layers:\n",
        "\n",
        "2D convolution with sixteen\n",
        " kernels\n",
        "ReLU activation\n",
        "Max pooling with\n",
        " kernels (and a stride of\n",
        ")"
      ],
      "metadata": {
        "id": "B2x2zIeYESY0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duJNCn8jETaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.13: Add three more layers to the network.\n",
        "\n",
        "2D convolution with thirty-two\n",
        " kernels\n",
        "ReLU activation\n",
        "Max pooling with\n",
        " kernels"
      ],
      "metadata": {
        "id": "Zve2J94TEOup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4)\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bpVl5FK0EiLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add these layers to the model\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "SSVQooUDEl0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "676lbBCpEmuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the new layers\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),  # [32, 3, 224, 224] -> [32, 16, 224, 224]\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),                                          # -> [32, 16, 56, 56]\n",
        "\n",
        "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1), # -> [32, 32, 56, 56]\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),                                          # -> [32, 32, 14, 14]\n",
        "\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # -> [32, 64, 14, 14]\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),                                          # -> [32, 64, 3, 3]\n",
        "\n",
        "    nn.Flatten()                                                                    # -> [32, 64 * 3 * 3] = [32, 576]\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "gamMI4dLJXt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.15: Add the final layers to the model\n",
        "\n",
        "Drop-out (with\n",
        ")\n",
        "Linear layer with\n",
        " outputs (check the summary above to get the correct number of inputs)\n",
        "ReLU activation\n",
        "Drop-out\n",
        "Linear output layer with the appropriate number of output"
      ],
      "metadata": {
        "id": "vPbNMnLDJyie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the final layers\n",
        "model = nn.Sequential(\n",
        "    # Convolutional Layers\n",
        "    nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),     # [32, 3, 224, 224] → [32, 16, 224, 224]\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),                    # → [32, 16, 56, 56]\n",
        "\n",
        "    nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),    # → [32, 32, 56, 56]\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),                    # → [32, 32, 14, 14]\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),    # → [32, 64, 14, 14]\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=4, stride=4),                    # → [32, 64, 3, 3]\n",
        "\n",
        "    # Flatten the features\n",
        "    nn.Flatten(),                                             # → [32, 64 * 3 * 3] = [32, 576]\n",
        "\n",
        "    # Fully Connected (Dense) Layers\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(576, 500),                                      # → [32, 500]\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(500, 9)                                         # → [32, 9] (for 9 output classes)\n",
        ")\n"
      ],
      "metadata": {
        "id": "sPn-4InWJzM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "Szvl-IV7KgWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.16:\n",
        "\n",
        "Prepare for training. Define the loss function, create an optimizers, and send the model to the GPU device."
      ],
      "metadata": {
        "id": "hYkaHm3RKhBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "q2zoujkoKkbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.17:\n",
        "\n",
        "Train model for\n",
        " epochs"
      ],
      "metadata": {
        "id": "PjCuvo7PLnm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 10\n",
        "# Train the model for 10 epochs\n",
        "train(model, optimizer, loss_fn, train_loader, val_loader, epochs, device)"
      ],
      "metadata": {
        "id": "WlauQ5dYLre3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model Performance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Task 1.5.18:\n",
        "\n",
        "Make predictions for all of the images in the validation set. Start by calculating the probabilities using the predict function (from our training.py module). And then calculate the predicted class based in the probabilities."
      ],
      "metadata": {
        "id": "GEl03KyvLvEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't change this\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "cm = confusion_matrix(targets,predictions.cpu())\n",
        "\n",
        "# Get the class names\n",
        "classes = class_distribution\n",
        "\n",
        "# Display the confusion matrix (don't change this)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\", ax=ax)"
      ],
      "metadata": {
        "id": "biNK27pIRAZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.19:\n",
        "\n",
        "Create the confusion matrix for the predictions on the validation set. We have provided the actual classes in the targets variable."
      ],
      "metadata": {
        "id": "Y4w6GWA-Ujq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "\n",
        "for _, labels in tqdm(val_loader):\n",
        "    targets.extend(labels.tolist())"
      ],
      "metadata": {
        "id": "LO-vzNGCUg2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't change this\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "cm = confusion_matrix(targets,predictions.cpu())\n",
        "\n",
        "# Get the class names\n",
        "classes = class_distribution\n",
        "\n",
        "# Display the confusion matrix (don't change this)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\", ax=ax)"
      ],
      "metadata": {
        "id": "L6g5EMSnUd4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1.5.20:\n",
        "\n",
        "Create a data set for the test data. It is located in the sea_creatures/test directory. Then create a data loader from this data set. DO NOT shuffle this data!"
      ],
      "metadata": {
        "id": "kpkJzSS9SknK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir =os.path.join(\"sea_creatures/train\")\n",
        "\n",
        "test_dataset =  datasets.ImageFolder(root='sea_creatures/test', transform=transform)\n",
        "\n",
        "print(\"Number of test images:\", len(test_dataset))\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ocmw78MATcZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5.21\n",
        "Make a prediction for each of the test images\n",
        "\n"
      ],
      "metadata": {
        "id": "Ltu934x0LwDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the probabilities for each test image\n",
        "test_probabilities = predict(model,val_loader,device)\n",
        "\n",
        "# Get the index associated with the largest probability for each test image\n",
        "test_predictions = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "print(\"Number of predictions:\", test_predictions.shape)"
      ],
      "metadata": {
        "id": "8vU1wEweSO9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ":Final checks\n",
        "You can now check how accurate your model is by sampling some images from our /test directory. These images are not labled, so you'll need to check it manually.\n",
        "\n",
        "The code below randomly samples 12 images from the test directory and shows them in a grid alongside its predicted label. Run it as many times as you want to get different samples.\n",
        "\n",
        "How is it working?"
      ],
      "metadata": {
        "id": "V_pCxrzfL3se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Sample 12 random indices from the test dataset\n",
        "sample_indices = random.sample(range(len(test_loader.dataset.samples)), 12)\n",
        "\n",
        "# Create a grid of 4x3 subplots\n",
        "fig, axes = plt.subplots(4, 3, figsize=(20, 10))\n",
        "\n",
        "# Iterate over the sampled indices and plot the corresponding images\n",
        "for ax, idx in zip(axes.flatten(), sample_indices):\n",
        "    image_path = test_loader.dataset.samples[idx][0]\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Display the image on the axis\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Get the predicted class for this image\n",
        "    predicted_class = test_classes[idx]\n",
        "\n",
        "    # Set the title of the subplot to the predicted class\n",
        "    ax.set_title(f\"Predicted: {predicted_class}\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "G6O6eXoSUIIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nCEtKA_TLy-6"
      }
    }
  ]
}
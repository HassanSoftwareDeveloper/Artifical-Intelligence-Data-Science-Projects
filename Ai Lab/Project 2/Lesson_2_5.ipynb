{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning and callback"
      ],
      "metadata": {
        "id": "S0MH0j4nKIJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary: In this lesson, we'll build another classifier model that predicts the crop disease on images of cassava plants from Uganda. We'll again use Transfer Learning, where a model trained for a task is reused as the starting point for a model on a different task. We'll also delve into Callbacks, which are powerful tools to customize the behavior of your model during training. Specifically, we'll focus on Learning Rate Scheduling, Checkpointing, and Early Stopping to enhance our model's training process.\n",
        "\n",
        "Objectives:\n",
        "\n",
        "Read in data with multiple classes\n",
        "\n",
        "Transform data and prepare it for training\n",
        "\n",
        "\n",
        "Use Transfer Learning to train a classifier model on cassava images\n",
        "\n",
        "Improve training by implementing various callbacks\n",
        "\n",
        "Prepare a submission for our competition by reformatting network predictions on the test set\n",
        "New Terms:\n",
        "\n",
        "Callbacks\n",
        "\n",
        "Learning Rate Scheduling\n",
        "\n",
        "Checkpointing\n",
        "\n",
        "Early Stopp"
      ],
      "metadata": {
        "id": "DhaeGSwTKChU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "PlcWohl2Kuvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch6M3ESKK3RJ",
        "outputId": "642b84a6-3b47-4273-9a09-aa78201f9f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFxD71xpKBob"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchinfo\n",
        "import torchvision\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch version : \", torch.__version__)\n",
        "print(\"torchvision version : \", torchvision.__version__)\n",
        "print(\"torchinfo version : \", torchinfo.__version__)\n",
        "print(\"numpy version : \", np.__version__)\n",
        "print(\"matplotlib version : \", matplotlib.__version__)\n",
        "\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j43kW2wUK_OJ",
        "outputId": "c98f7c21-5a39-46ea-c56c-737ebb2d28ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version :  2.6.0+cu124\n",
            "torchvision version :  0.21.0+cu124\n",
            "torchinfo version :  1.8.0\n",
            "numpy version :  2.0.2\n",
            "matplotlib version :  3.10.0\n",
            "Python 3.11.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXPHQJqJLPwR",
        "outputId": "e5d1c1dc-abcc-4bdf-8fd1-fbdd6b19cb6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is in the data_p2 directory within which is the data_undersampled directory. In that folder we have the train subdirectory that contains the training data."
      ],
      "metadata": {
        "id": "mKAoD0fTLlkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "T**ask 2.5.1: Assign data_dir the path to the training data using os.path.join. **"
      ],
      "metadata": {
        "id": "workVi2NMbI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "859pIW0cPKn4",
        "outputId": "d56970bf-fa13-4a01-b924-fdb30f77d04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09281da7-6d38-4491-8ab5-84a4a1fc6840\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-09281da7-6d38-4491-8ab5-84a4a1fc6840\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3703241522.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=\"archive\"\n",
        "train_dir=os.path.join(\"data_dir\",\"PlantVillage\")\n",
        "print(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixguOctxODJ5",
        "outputId": "54ac85d7-4888-4a73-e394-d020be52000d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_dir/PlantVillage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=os.listdir(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "av2immedOsO5",
        "outputId": "7fd11775-6e12-4baa-af1f-bfd52e9cde29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data_dir/PlantVillage'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2245572143.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_dir/PlantVillage'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=os.listdir('data_p2/data_undersampled/train')\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "ofzZOHogLSDQ",
        "outputId": "28620925-cee2-4479-c2b9-e2403eef5717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data_p2/data_undersampled/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2527911793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_p2/data_undersampled/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_p2/data_undersampled/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.2: Create a list of class names in this data using os.listdir.**"
      ],
      "metadata": {
        "id": "9BWQbmSFRCib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = os.listdir(data_dir)\n",
        "\n",
        "print(\"List of classes:\", classes)"
      ],
      "metadata": {
        "id": "2NbKkD9tRDvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ddvr8U2mRGrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in the previous lessons, we'll standardize the images using the following set of transformations:\n",
        "\n",
        "Convert any grayscale images to RGB format with a custom class\n",
        "Resize the image, so that they're all the same size (we chose\n",
        " x\n",
        ")\n",
        "Convert the image to a Tensor of pixel values\n",
        "Normalize the data\n",
        "Here's the custom transfo"
      ],
      "metadata": {
        "id": "Q5x3yrGTRLL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToRGB(object):\n",
        "    def __call__(self, img):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        return img"
      ],
      "metadata": {
        "id": "iGx756OkRI8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's make the transformation pipeline. In the normalization step, use the mean and std values from our previous lesson."
      ],
      "metadata": {
        "id": "SnxcykbGRNp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.3: Create the transformation pipeline using transforms.Compose from torchvision package. Follow what we did in the previous lessons.**"
      ],
      "metadata": {
        "id": "JZwQJ7Y6RQkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_normalized = transforms.Compose([\n",
        "    ConvertToRGB(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225))\n",
        "])\n",
        "\n",
        "print(type(transform_normalized))\n",
        "print(\"----------------\")\n",
        "print(transform_normalized)"
      ],
      "metadata": {
        "id": "fefrYALJRPyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.4: Make a dataset using ImageFolder from datasets and make sure to apply transform_normalized transformation pipeline. Then print the length of the dataset.**"
      ],
      "metadata": {
        "id": "ES6Z83JsSdW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_dataset = datasets.ImageFolder(root=data_dir,transform=transform_normalized)\n",
        "\n",
        "\n",
        "print('Length of dataset:', len(normalized_dataset))"
      ],
      "metadata": {
        "id": "Z0veJ_aSRLzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Making a train/validation split**\n",
        "\n",
        "As usual, we'll divide our data into two parts. One part is for training the model, the other part is for evaluating it on unseen images.\n",
        "\n",
        "**Task 2.5.5: Use random_split to create a 80/20 split (training dataset should have 80% of the data, validation dataset should have 20% of the data).**"
      ],
      "metadata": {
        "id": "fEbKLy9nSzvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Important, don't change this!\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "train_dataset, val_dataset = random_split(normalized_dataset,[0.8,0.2] ,generator=g)\n",
        "\n",
        "print(\"Length of training dataset:\", len(train_dataset))\n",
        "print(\"Length of validation dataset:\", len(val_dataset))\n",
        "\n",
        "percent_train = np.round(100 * len(train_dataset) / len(normalized_dataset), 2)\n",
        "percent_val = np.round(100 * len(val_dataset) / len(normalized_dataset), 2)\n",
        "\n",
        "print(f\"Train data is {percent_train}% of full data\")\n",
        "print(f\"Validation data is {percent_val}% of full data\")"
      ],
      "metadata": {
        "id": "rRHLz52wTRG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.6: Use class_counts function on the train_dataset and visualize the results with a bar chart.**"
      ],
      "metadata": {
        "id": "aG9s-PPA_hQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from training import class_counts\n",
        "\n",
        "train_counts = class_counts(train_dataset)\n",
        "\n",
        "# Make a bar chart from the function output\n",
        "\n",
        "# Add axis labels and title\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Frequency [count]\")\n",
        "plt.title(\"Distribution of Classes in Training Dataset\");"
      ],
      "metadata": {
        "id": "jOuHGf7c_qCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.7: Use the class_counts function on the validation split. Make sure to again visualize the results with a bar chart.**"
      ],
      "metadata": {
        "id": "EEbGR8nk_1GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_counts = class_counts(val_dataset)\n",
        "\n",
        "# Make a bar chart from the function output\n",
        "val_counts.sort_values().plot(kind=\"bar\")\n",
        "# Add axis labels and title\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Frequency [count]\")\n",
        "plt.title(\"Distribution of Classes in Validation Dataset\");"
      ],
      "metadata": {
        "id": "VksQjSS1AyrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create DataLoader objects. We'll use a batch size of 32 and create one DataLoader for training and another for validation data. Remember that in training we want to shuffle the data after each epoch and in validation we don't."
      ],
      "metadata": {
        "id": "K9Ktg0gq_33z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.8: Create the training loader (with shuffling on) and the validation loader (with shuffling off).**"
      ],
      "metadata": {
        "id": "SkwdxOFc_-GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "print(type(train_loader))\n",
        "print(type(val_loader))"
      ],
      "metadata": {
        "id": "-1UQ5n-3A0x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Selection for Transfer Learning**\n",
        "When we're using Transfer Learning, choosing the right pre-trained model is crucial. We'll select the same model as in the previous lesson. This model has been trained on a large and diverse dataset, ensuring it has learned features that are broadly applicable to various tasks, including ours"
      ],
      "metadata": {
        "id": "Jkx27UNRABSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Task 2.5.9: Define a resnet50 model in the same way we defined it in the previous lesson.**"
      ],
      "metadata": {
        "id": "Wrxu73rbAILz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "2Jk3gJAPBg-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.10: Fix the parameters of the model such that they'll not be updated once we train the model on our task. Remember how we did this in the previous lesson?**"
      ],
      "metadata": {
        "id": "pdrX1PGQANZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the models weights\n",
        "for params in model.parameters():\n",
        "    params.requires_grad=False\n",
        "print(model)"
      ],
      "metadata": {
        "id": "_Kq5471gB3EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same as we did before, we now want to change the output layer of the model (layer model.fc). We want to replace it with a dense layer and an output layer.\n",
        "\n",
        "But we need to know how many features will be going into the dense layer that we want to add. This means we should first compute the number of features going into the last layer of the original model."
      ],
      "metadata": {
        "id": "eVWa1rdrB91b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.11: Compute the number of features going into the last layer of the original model.**"
      ],
      "metadata": {
        "id": "0_tDqQMMB_dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_feat = model.fc.in_features\n",
        "\n",
        "print(in_feat)"
      ],
      "metadata": {
        "id": "4vEhfS4pCDQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well done! Now we can change the last layer (layer model.fc). We want to change it to:\n",
        "\n",
        "a dense layer with 256 neurons\n",
        "followed by ReLU activation\n",
        "then add p=0.5 of Dropout\n",
        "followed by the output layer with 5 neurons (because our data has 5 classes)"
      ],
      "metadata": {
        "id": "gf2dHP0yCCrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Task 2.5.12: Fill in the missing parts of code below that changes the last layer of the original model.**"
      ],
      "metadata": {
        "id": "NU94E8VcCLhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modified_last_layer = nn.Sequential()\n",
        "\n",
        "modified_last_layer.append(nn.Linear(in_feat, 256))\n",
        "\n",
        "relu = nn.ReLU()\n",
        "modified_last_layer.append(relu)\n",
        "\n",
        "modified_last_layer.append(nn.Dropout(p=0.5))\n",
        "\n",
        "linear = nn.Linear(256,5)\n",
        "modified_last_layer.append(linear)\n",
        "\n",
        "model.fc = modified_last_layer\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "QpfQXwuwCri8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**\n",
        "As always, before we start training, we need to define the loss and what optimizer we'll use. For loss function we'll go with cross entropy. For the optimizer we'll choose the Adam optimizer as we've done before."
      ],
      "metadata": {
        "id": "WOw0P5HGCukz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.13: Define cross-entropy as the loss function and set Adam optimizer to be the optimizer. You can use the default learning rate and weight_decay=1e-4.**"
      ],
      "metadata": {
        "id": "X72OxsYkCyC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn =nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),weight_decay=1e-4)\n",
        "\n",
        "print(loss_fn)\n",
        "print(\"----------------------\")\n",
        "print(optimizer)"
      ],
      "metadata": {
        "id": "FvfQYPdQCv5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.14: Place our model on device. The code we provided below prints out the device that the model is on.**"
      ],
      "metadata": {
        "id": "B-1BpR3uDMR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Place model on device\n",
        "model.to(device)\n",
        "print(next(model.parameters()).device)"
      ],
      "metadata": {
        "id": "OIYB-pjyDV78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.15: Complete the input_size tuple that we are passing to summary function in the code below.**"
      ],
      "metadata": {
        "id": "xhyZpfmbDYTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height = 224\n",
        "width = 224\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, height, width))"
      ],
      "metadata": {
        "id": "FcNkbWvVDsWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among other things, the output of the summary displays the amount of trainable parameters the model has. And it has many!\n",
        "\n",
        "\n",
        "While we added Dropout, which helps with preventing overfitting, we'll go further and take another step to make sure we don't overfit. When we fit, we'll check model performance at every epoch and stop fitting when the model stops improving. This brings us to callbacks!\n",
        "\n",
        "\n",
        "**Training the Model with Callbacks**\n",
        "\n",
        "During the training of our model, we can use various callbacks. Callbacks allow us to customize and control the training process in fine-grained ways. We'll implement three key callbacks:\n",
        "\n",
        "Learning Rate Scheduling: Adjusts the learning rate over time, which can lead to better model performance.\n",
        "\n",
        "Early Stopping: Halts training when the model's performance stops improving, which prevents overfitting. We'll stop if validation loss doesn't improve for at least 5 epochs.\n",
        "\n",
        "Checkpointing: Saves the model every time validation loss gets better than in the epoch prior. This allows us to recover the best model once training completes.\n",
        "\n",
        "In order to use these callbacks, we need to implement them and then update the train function.\n",
        "\n",
        "For the Learning Rate Scheduling, we'll use StepLR from torch.optim. The StepLR scheduler decays the learning rate by multiplicative factor gamma every step_size epochs."
      ],
      "metadata": {
        "id": "Wl5x4LpODw9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.16: Set step_size to and gamma factor to The rest of the code creates a StepLR Learning Rate Scheduler**."
      ],
      "metadata": {
        "id": "Jww5dI3FEH7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Period of learning rate decay\n",
        "step_size = 4\n",
        "# Multiplicative factor of learning rate decay\n",
        "gamma = 0.2\n",
        "\n",
        "# Initialize the learning rate scheduler\n",
        "scheduler = StepLR(\n",
        "    optimizer,\n",
        "    step_size=step_size,\n",
        "    gamma=gamma,\n",
        ")\n",
        "\n",
        "print(type(scheduler))"
      ],
      "metadata": {
        "id": "lzXTd8cYEVBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Early Stopping, we'll create a function early_stopping that we'll call from within the train function. The early_stopping function accepts:\n",
        "\n",
        "the current validation loss,\n",
        "the best validation loss so far\n",
        "the number of epochs since validation loss last improved (counter).\n",
        "In the function we need to check if validation loss improved. If yes, we reset the counter. If not, we add one to the counter. We also need to check if validation loss hasn't improved in the last 5 epochs. If that is the case, we should set stopping to True."
      ],
      "metadata": {
        "id": "dvcqUuIxE9aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.17: Fill in the missing code in the definition of the early_stopping function below.**"
      ],
      "metadata": {
        "id": "s6c5Cnw4FAec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def early_stopping(validation_loss, best_val_loss, counter):\n",
        "    stop = False\n",
        "\n",
        "    if validation_loss < best_val_loss:\n",
        "        counter = 0   # Reset counter if model improved\n",
        "    else:\n",
        "        counter += 1  # Increase counter if no improvement\n",
        "\n",
        "    if counter >= 5:  # If no improvement for 5 epochs\n",
        "        stop = True   # Tell training to stop\n",
        "\n",
        "    return counter, stop"
      ],
      "metadata": {
        "id": "4YQoAYCGFAK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll define a function that will take care of Checkpointing. In this function we need to check if validation loss improved. If yes, we save the model."
      ],
      "metadata": {
        "id": "XWvWME9HF_WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpointing(validation_loss, best_val_loss, model, optimizer, save_path):\n",
        "\n",
        "    if validation_loss < best_val_loss:\n",
        "        torch.save(\n",
        "            {\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"loss\": best_val_loss,\n",
        "            },\n",
        "            save_path,\n",
        "        )\n",
        "        print(f\"Checkpoint saved with validation loss {validation_loss:.4f}\")"
      ],
      "metadata": {
        "id": "SQbBEMa3F9p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to modify the train function to include an option to use Callbacks.\n",
        "\n",
        "Notice that the modified train function below is quite similar to what we've used before. We just added scheduler, checkpoint_path and early_stopping as optional arguments. As you can see at the end of the modified train function, we use these three callbacks when function is called with appropriate inputs."
      ],
      "metadata": {
        "id": "oQhVFJ1nGCD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from training import score, train_epoch\n",
        "\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=20,\n",
        "    device=\"cpu\",\n",
        "    scheduler=None,\n",
        "    checkpoint_path=None,\n",
        "    early_stopping=None,\n",
        "):\n",
        "    # Track the model progress over epochs\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    learning_rates = []\n",
        "\n",
        "    # Create the trackers if needed for checkpointing and early stopping\n",
        "    best_val_loss = float(\"inf\")\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    print(\"Model evaluation before start of training...\")\n",
        "    # Test on training set\n",
        "    train_loss, train_accuracy = score(model, train_loader, loss_fn, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    # Test on validation set\n",
        "    validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
        "    val_losses.append(validation_loss)\n",
        "    val_accuracies.append(validation_accuracy)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(\"\\n\")\n",
        "        print(f\"Starting epoch {epoch}/{epochs}\")\n",
        "\n",
        "        # Train one epoch\n",
        "        train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
        "\n",
        "        # Evaluate training results\n",
        "        train_loss, train_accuracy = score(model, train_loader, loss_fn, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Test on validation set\n",
        "        validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
        "        val_losses.append(validation_loss)\n",
        "        val_accuracies.append(validation_accuracy)\n",
        "\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.4f}%\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print(f\"Validation accuracy: {validation_accuracy*100:.4f}%\")\n",
        "\n",
        "        # # Log the learning rate and have the scheduler adjust it\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        learning_rates.append(lr)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Checkpointing saves the model if current model is better than best so far\n",
        "        if checkpoint_path:\n",
        "            checkpointing(\n",
        "                validation_loss, best_val_loss, model, optimizer, checkpoint_path\n",
        "            )\n",
        "\n",
        "        # Early Stopping\n",
        "        if early_stopping:\n",
        "            early_stopping_counter, stop = early_stopping(\n",
        "                validation_loss, best_val_loss, early_stopping_counter\n",
        "            )\n",
        "            if stop:\n",
        "                print(f\"Early stopping triggered after {epoch} epochs\")\n",
        "                break\n",
        "\n",
        "        if validation_loss < best_val_loss:\n",
        "            best_val_loss = validation_loss\n",
        "\n",
        "    return (\n",
        "        learning_rates,\n",
        "        train_losses,\n",
        "        val_losses,\n",
        "        train_accuracies,\n",
        "        val_accuracies,\n",
        "        epoch,\n",
        "    )"
      ],
      "metadata": {
        "id": "O7MtUHxiGGGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our model and callbacks ready, we'll proceed to train the model. During this phase, we'll observe how callbacks affect the training process and ultimately, the model's performance.\n",
        "\n",
        "Because we implemented early stopping, the model will stop training once its performance no longer improves. So we can set off to train for many epochs and training will stop when the model stops improving."
      ],
      "metadata": {
        "id": "b_5Z0zdoGTPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.18: Define the number of training epochs to equal 50. The rest of the code provided below will call the train function and start the training. Note that this can take a while to run.**"
      ],
      "metadata": {
        "id": "WQK584S5GlU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regarding Model Training Times\n",
        "This task involves training the model for (at least) 50 epochs. This might take more than 60 minutes. Instead, we recommend you to skip the training process and load the pre-trained model that we have made available in the next few cells.\n",
        "\n",
        "We strongly recommend you to use the saved model instead of training your own"
      ],
      "metadata": {
        "id": "Ajg3OBH1GoLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_to_train = 50\n",
        "\n",
        "train_results = train(\n",
        "    model,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=epochs_to_train,\n",
        "    device=device,\n",
        "    scheduler=scheduler,\n",
        "    checkpoint_path=\"model/LR_model.pth\",\n",
        "    early_stopping=early_stopping,\n",
        ")\n",
        "\n",
        "(\n",
        "    learning_rates,\n",
        "    train_losses,\n",
        "    valid_losses,\n",
        "    train_accuracies,\n",
        "    valid_accuracies,\n",
        "    epochs,\n",
        ") = train_results"
      ],
      "metadata": {
        "id": "tiiDn_yhGS2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[RECOMMENDED] Load the pre-trained model:"
      ],
      "metadata": {
        "id": "D5UBG5nQGzCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "model = torch.load(\"model_trained.pth\", weights_only=False)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "o0sAbFCHGyQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the training indeed didn't go over all 50 epochs, but stopped earlier."
      ],
      "metadata": {
        "id": "hB5fxtpuG8Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training went on for {epochs} number of epochs before it stopped.\")"
      ],
      "metadata": {
        "id": "Xa_yY9riGs6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation of the Training Process and the Model**\n",
        "\n",
        "Now that the training's finished, we'll evaluate our model's performance and draw conclusions. We'll see how effectively our callbacks contributed to the training process and discuss the results. Let's first plot the learning curve!"
      ],
      "metadata": {
        "id": "Wk57_jb-G-Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "eval_metrics_df = pd.read_csv(\"pretrained_model_evaluation_metrics.csv\")\n",
        "train_losses = eval_metrics_df['train_losses'].values\n",
        "valid_losses = eval_metrics_df['valid_losses'].values\n",
        "train_accuracies = eval_metrics_df['train_accuracies'].values\n",
        "valid_accuracies = eval_metrics_df['valid_accuracies'].values\n",
        "learning_rates = eval_metrics_df['learning_rates'].dropna().values"
      ],
      "metadata": {
        "id": "i_GJgYKiHGSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(valid_losses, label=\"Validation Loss\")\n",
        "plt.ylim([0, 1.7])\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "9yYpOpHhHItl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.19: Complete the code below to plot train and validation accuracies. You can follow what we did above for plotting train and validation losses.**"
      ],
      "metadata": {
        "id": "7bhxILYTHkC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train accuracies, use label=\"Training Accuracy\"\n",
        "plt.plot(train_accuracies,label=\"Training Accuracy\")\n",
        "# Plot validation accuracies, use label=\"Validation Accuracy\"\n",
        "plt.plot(valid_accuracies,label=\"Validation Accuracy\")\n",
        "plt.ylim([0, 1])\n",
        "plt.title(\"Accuracy over epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "VC2tElA7HmZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the learning curve we see that overall training loss decreases and accuracy increases. Validation loss does not seem to improve that much beyond the first couple of epochs.\n",
        "\n",
        "Let's also inspect how the learning rate was changing during training due to the fact that we used a Learning Rate Scheduling Callback."
      ],
      "metadata": {
        "id": "DqjSeQPpHn_k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_5YGw2oFHt3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the learning rate decreases as our training progresses.\n",
        "\n",
        "Now it's time load the best model that we saved with checkpointing!"
      ],
      "metadata": {
        "id": "IeY-hup7HtUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model/LR_model.pth\")\n",
        "\n",
        "# Load the state dictionaries\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
      ],
      "metadata": {
        "id": "vaivvAoSHv7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model/LR_model.pth\")\n",
        "\n",
        "# Load the state dictionaries\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"]"
      ],
      "metadata": {
        "id": "LgTRMWaLH8os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ")\n",
        "Let's compute the confusion matrix for our model using the validation data, like we did in previous lessons.\n",
        "\n",
        "We'll obtain the probabilities that our model predicts by using the predict function from training.py. This function expects the model, the loader and the device as input arguments.\n",
        "\n",
        "**Task 2.5.20: Use the predict function from training.py to compute probabilities that our model predicts on the validation data. Then use torch.argmax and take these probabilities to compute the predicted classes.**"
      ],
      "metadata": {
        "id": "6cQvpoKEHxpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from training import predict\n",
        "\n",
        "probabilities_val = predict(model , val_loader, device)\n",
        "predictions_val =torch.argmax(probabilites_val)\n",
        "\n",
        "print(predictions_val)"
      ],
      "metadata": {
        "id": "2p2VGJPyIaLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_val = torch.cat([labels for _, labels in tqdm(val_loader, desc=\"Get Labels\")])\n",
        "\n",
        "cm = confusion_matrix(targets_val.cpu(), predictions_val.cpu())\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\");"
      ],
      "metadata": {
        "id": "r6uKePO7Ib50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well done, looks good! We're ready to use this model on our test set and prepare a CSV file that we can submit to the competition."
      ],
      "metadata": {
        "id": "M-B77nnYIjs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission to Competition**\n",
        "\n",
        "The competition submission should contain predicted probabilities for each of the\n",
        " classes on a test set. So we'll need to run each test image through our model.\n",
        "\n",
        "Let's first find the test images. They are located in the test subdirectory within the data_p2 directory.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Task 2.5.21: Assign test_dir the path to the test data using os.path.join.**"
      ],
      "metadata": {
        "id": "YAfbgoH-Iltd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The competition requires us to save the model predictions as a CSV file. The first column should be called ID and contains the image filename. The rest of the columns should be labeled by the class name.\n",
        "\n",
        "\n",
        "In order to get predicted probabilities of our model, we'll create a function file_to_confidence which is similar to what we created for this purpose in Project 1. The function makes model predictions on a single image. The steps in the function are:\n",
        "\n",
        "\n",
        "Open the image.\n",
        "Apply our transformation pipeline to the image as our model expects.\n",
        "Use unsqueeze to change the image tensor to 4D (\n",
        " x\n",
        " x\n",
        " x\n",
        ") as our model is expecting a batch of images.\n",
        "\n",
        "Place image on device we're using.\n",
        "\n",
        "Make prediction and pass it through a SoftMax to get probabilities (numbers between\n",
        " and\n",
        ", that sum to\n",
        ").\n",
        "Convert result to a DataFrame"
      ],
      "metadata": {
        "id": "c_nD_e4tIuA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = os.path.join('data_p2','test')\n",
        "print(test_dir)"
      ],
      "metadata": {
        "id": "JsOsjF6HJp4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A1KdON5WJrql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "\n",
        "def file_to_confidence(model, datadir, filename, transform_pipeline):\n",
        "    file_path = os.path.join(datadir, filename)\n",
        "    image = PIL.Image.open(file_path)\n",
        "    transformed = transform_pipeline(image)\n",
        "    unsqueezed = transformed.unsqueeze(0)\n",
        "    image_cuda = unsqueezed.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model_raw = model(image_cuda)\n",
        "        confidence = torch.nn.functional.softmax(model_raw, dim=1)\n",
        "\n",
        "    conf_df = pd.DataFrame([[filename] + confidence.tolist()[0]])\n",
        "    conf_df.columns = [\"ID\"] + train_dataset.dataset.classes\n",
        "\n",
        "    return conf_df"
      ],
      "metadata": {
        "id": "MbQ9zcaOJwst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just to make sure this is working, let's call this function on a training image from the cassava mosaic disease class for example."
      ],
      "metadata": {
        "id": "o6Kxa7VCJ0VN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYYWntzNJ0Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mosaic_train_dir = os.path.join(\"data_p2\", \"train\", \"cassava-mosaic-disease-cmd\")\n",
        "mosaic_images = os.listdir(mosaic_train_dir)\n",
        "\n",
        "file_to_confidence(model, mosaic_train_dir, mosaic_images[0], transform_normalized)"
      ],
      "metadata": {
        "id": "za_9P4k9Jyxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_to_confidence(model, mosaic_train_dir, mosaic_images[1], transform_normalized)"
      ],
      "metadata": {
        "id": "aSCQLD9zJ4xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything seems in order. Now let's use file_to_confidence function on each test image to get the predictions for the competition submission. We can loop over the filenames and build up a list of DataFrames."
      ],
      "metadata": {
        "id": "7rKKI9sZJ7FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5.22: Fill in the missing code below and use pd.concat to assemble the list of DataFrames small_dfs into one big DataFrame.**"
      ],
      "metadata": {
        "id": "-2vHPkqwJ9Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_dfs = []\n",
        "\n",
        "for filename in tqdm(os.listdir(test_dir), desc=\"Predicting on test set\"):\n",
        "    small_dfs.append(\n",
        "        file_to_confidence(model, test_dir, filename, transform_normalized)\n",
        "    )\n",
        "\n",
        "confidence_df = pd.concat(small_dfs)\n",
        "\n",
        "confidence_df = confidence_df.sort_values(\"ID\").reset_index(drop=True)\n",
        "confidence_df.head()"
      ],
      "metadata": {
        "id": "R14euhuUJ-Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "x4lb8GohKeVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Great! 🎉 We accomplished a lot in this notebook. Here are the key takeaways:\n",
        "\n",
        "We used Transfer Learning to take a large existing model and specialize it to our competition.\n",
        "We trained that model with the balanced dataset we created in an earlier lesson.\n",
        "We implemented Callbacks using additional code in the training loop.\n",
        "The Callbacks we implemented were: Learning Rate Scheduling, Checkpointing, and Early Stopping.\n",
        "By reformatting the predictions of the model on the test set, we obtained a CSV file for competition submission."
      ],
      "metadata": {
        "id": "n5saHdbOKAoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_8LSgmjfJ2HV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PX3rTqeuGw3N"
      }
    }
  ]
}